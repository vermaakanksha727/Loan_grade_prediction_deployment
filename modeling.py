# -*- coding: utf-8 -*-
"""Modeling.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1LA4CxNUVaNuRKnbWK6os9H_r6vusz5vH

# ***Modeling-***
"""

# Import Libraries
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

import warnings
warnings.filterwarnings("ignore")

from google.colab import drive
drive.mount('/content/drive')

model_df= pd.read_csv("/content/drive/MyDrive/model_accepted.csv")

# print the first five rows of the DataFrame
model_df.head()

# print the list of columns in the dataset to find the name of the prediction target
model_df.shape

"""# Selecting The Prediction Target"""

model_df['grade'] = model_df['grade'].map({'A':1,'B':2,'C':3,'D':4,'E':5,'F':6,'G':7})

"""# Choosing "Features""""

# Select data corresponding to features in feature_names
X=model_df.drop(['Unnamed: 0','grade'],axis=1)
y=model_df['grade']

# printing the shape of the data (rows,columns)
X.shape

y

"""# ***Logistic Regression-***

# Splitting our Data
"""

from sklearn.model_selection import train_test_split
# split data into training and validation data, for both features and target
train_X, test_X, train_y, test_y = train_test_split(X, y, test_size= 0.2, random_state=1)

print( train_X.shape, test_X.shape, train_y.shape, test_y.shape)

"""# FEATURE SCALING

Standardisation
"""

from sklearn.preprocessing import StandardScaler
ss = StandardScaler()
train_X = ss.fit_transform(train_X)
test_X = ss.fit_transform(test_X)

"""# Specify and Fit the Model"""

from sklearn.linear_model import LogisticRegression
# Defining model
accepted_model = LogisticRegression(penalty='none')

# Fitting model
accepted_model.fit(train_X, train_y)

val_predictions = accepted_model.predict(test_X)

val_predictions

# Comparing Actual Data vs Predicted Data
compare_grades = pd.DataFrame({'Actual':test_y, 'Predicted':val_predictions})
compare_grades

"""# MODEL EVALUATION"""

from sklearn.metrics import confusion_matrix, accuracy_score, classification_report,  r2_score,mean_squared_error, mean_absolute_error

confusion = confusion_matrix(test_y, val_predictions)
print(" \n Confusion Matrix is : \n", confusion)

fig, ax = plt.subplots()
# create heatmap
sns.heatmap(confusion, annot=True, fmt='d', cmap='YlGnBu')
ax.xaxis.set_label_position("top")
plt.tight_layout()
plt.title('Confusion matrix', y=1.1)
plt.ylabel('Actual label')
plt.xlabel('Predicted label')

print('Accuray: {}'.format(accepted_model.score(train_X,train_y)))
print("Accuracy: {}".format(accepted_model.score(test_X, test_y)))

import pickle
pickle.dump(accepted_model,open('loan_model.pkl','wb'))

loaded_model=pickle.load(open('loan_model.pkl','rb'))
result=loaded_model.score(test_X,test_y)
print(result)

